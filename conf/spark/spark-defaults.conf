# Кластер
spark.master                              spark://spark-master:7077
spark.driver.bindAddress                  0.0.0.0
spark.driver.host                         jupyter

# S3A / MinIO
spark.hadoop.fs.s3a.endpoint              http://minio:9000
spark.hadoop.fs.s3a.path.style.access     true
spark.hadoop.fs.s3a.connection.ssl.enabled false
spark.hadoop.fs.s3a.impl                  org.apache.hadoop.fs.s3a.S3AFileSystem
# Доступ (либо creds через ENV, как в compose; либо оставить строки доступа здесь):
spark.hadoop.fs.s3a.access.key            minio
spark.hadoop.fs.s3a.secret.key            minio_minio

# Iceberg (под текущие пути)
spark.sql.extensions                      org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
# spark.sql.catalog.bronze                  org.apache.iceberg.spark.SparkCatalog
# spark.sql.catalog.bronze.type             hadoop
# spark.sql.catalog.bronze.warehouse        s3a://warehouse/bronze
# (можно единый каталог, позже поменяем на:
spark.sql.catalog.ice                       org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.ice.type                  hadoop
spark.sql.catalog.ice.warehouse             s3a://warehouse/iceberg/
spark.sql.defaultCatalog                    ice
# и таблицы станут ice.bronze.*)

# Производительность/ресурсы
spark.serializer                          org.apache.spark.serializer.KryoSerializer
spark.sql.shuffle.partitions              48
spark.executor.instances                  1
spark.executor.cores                      1
spark.executor.memory                     2g
spark.driver.memory                       3g
spark.cores.max                           1

spark.dynamicAllocation.enabled           false

spark.driver.extraJavaOptions             -Duser.name=spark
spark.executor.extraJavaOptions           -Duser.name=spark
