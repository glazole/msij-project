services:
  minio:
    image: minio/minio:latest
    container_name: minio
    command: ["server", "/data", "--console-address", ":9001"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://minio:9000/minio/health/ready"]
    environment:
      MINIO_DOMAIN: minio
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio_minio
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio
    ports: ["9000:9000", "9001:9001"]
    volumes:
      - /home/glazole/msij-project/minio:/data

  mc:
    image: minio/mc:latest
    container_name: mc
    depends_on:
      minio:
        condition: service_healthy
    networks: [iceberg_net]
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio_minio
      AWS_REGION: us-east-1
    entrypoint: >
      /bin/sh -c "
      sleep 3 &&
      mc alias set local http://minio:9000 minio minio_minio &&
      mc mb -p local/raw local/stage local/warehouse local/warehouse/spark-events || true &&
      tail -f /dev/null
      "

  spark-master:
    build: ./docker/spark
    image: glazole/spark-master-rest:custom
    container_name: spark-master
    hostname: spark-master
    networks: [iceberg_net]
    depends_on:
      minio:
        condition: service_healthy
      mc:
        condition: service_started
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_UI_PORT: 8080
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio_minio
      AWS_EC2_METADATA_DISABLED: "true"
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - /home/glazole/msij-project/conf/spark:/opt/bitnami/spark/conf
      - /home/glazole/msij-project/work:/work
      - /mnt/e/crpt_2025:/win_df

  spark-worker:
    image: glazole/spark-master-rest:custom
    container_name: spark-worker
    hostname: spark-worker
    networks: [iceberg_net]
    depends_on:
      spark-master:
        condition: service_started
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio_minio
      AWS_EC2_METADATA_DISABLED: "true"
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 8G
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 10G
    ports:
      - "8081:8081"
    volumes:
      - /home/glazole/msij-project/conf/spark:/opt/bitnami/spark/conf
      - /home/glazole/msij-project/work:/work
      - /mnt/e/crpt_2025:/win_df

  jupyter:
    image: glazole/spark-jupyter-rest:custom
    user: "1001:1001"
    build:
      context: .
      dockerfile: docker/jupyter/Dockerfile
    container_name: jupyter
    hostname: jupyter
    networks: [iceberg_net]
    depends_on:
      spark-master:
        condition: service_started
    ports:
      - "8888:8888"
      - "4040:4040"
    working_dir: /work
    environment:
      JUPYTER_TOKEN: "lab"
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio_minio
      AWS_EC2_METADATA_DISABLED: "true"
      HOME: /work
      JUPYTER_CONFIG_DIR: /work/.jupyter
      JUPYTER_DATA_DIR: /work/.jupyter
      JUPYTER_RUNTIME_DIR: /work/.jupyter/runtime
      JUPYTERLAB_WORKSPACES_DIR: /work/.jupyter/lab/workspaces
      SPARK_SUBMIT_OPTS: "-Dfs.s3a.metrics.skip=true"
      PYSPARK_SUBMIT_ARGS: >
        --master spark://spark-master:7077
        --conf spark.driver.bindAddress=0.0.0.0
        --conf spark.driver.host=jupyter
        pyspark-shell
    command: >
      bash -c "
        mkdir -p /work/.jupyter/lab/workspaces /work/.jupyter/lab/user-settings /work/.jupyter/runtime &&
        jupyter lab --ip=0.0.0.0 --no-browser
        --NotebookApp.notebook_dir=/work
        --ServerApp.token=$$JUPYTER_TOKEN
      "
    volumes:
      - /home/glazole/msij-project/conf/spark:/opt/bitnami/spark/conf
      - /home/glazole/msij-project/work:/work

  # === PostgreSQL для Iceberg Catalog ===
  postgresql:
    image: postgres:15-alpine
    container_name: postgresql
    hostname: postgresql
    networks: [iceberg_net]
    environment:
      POSTGRES_DB: iceberg_catalog
      POSTGRES_USER: iceberg
      POSTGRES_PASSWORD: iceberg
    ports:
      - "5432:5432"
    volumes:
      - pg_iceberg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U iceberg -d iceberg_catalog"]
      interval: 10s
      timeout: 5s
      retries: 5

  # === Iceberg REST Catalog ===
  iceberg-rest:
    image: apache/iceberg-rest-fixture
    container_name: iceberg-rest
    hostname: iceberg-rest
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'iceberg-rest' > /dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: [iceberg_net]
    depends_on:
      postgresql:
        condition: service_healthy
      spark-master:
        condition: service_started
    ports:
      - "8181:8181"
    environment:
      # === Основные параметры каталога ===
      CATALOG_WAREHOUSE: s3://warehouse/iceberg/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      # === JDBC Catalog реализация ===
      CATALOG_IMPL: org.apache.iceberg.jdbc.JdbcCatalog
      CATALOG_URI: jdbc:postgresql://postgresql:5432/iceberg_catalog
      CATALOG_JDBC_USER: iceberg
      CATALOG_JDBC_PASSWORD: iceberg
      # === Доступ к MinIO / S3 ===
      CATALOG_S3_ENDPOINT: http://minio:9000
      # === AWS-совместимые параметры ===
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio_minio
      LOG_LEVEL: INFO
    volumes:
      - /home/glazole/msij-project/jars/postgresql-42.7.2.jar:/app/libs/postgresql-42.7.2.jar
      - /home/glazole/msij-project/conf/spark:/opt/spark/conf
      - /home/glazole/msij-project/work:/work
    command: >
      java -cp "/usr/lib/iceberg-rest/iceberg-rest-adapter.jar:/app/libs/postgresql-42.7.2.jar" 
      org.apache.iceberg.rest.RESTCatalogServer

volumes:
  minio-data:
  spark-logs:
  pg_iceberg_data:

networks:
  iceberg_net:
    driver: bridge
